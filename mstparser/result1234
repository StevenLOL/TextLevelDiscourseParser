train 18 non-projective model
Creating Alphabet ... Done.
Num Features: 434764
Creating Feature Vector Instances: 
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 
Num Features: 434764
Num Feats: 434764.	Num Edge Labels: 20
 Iteration 0[342|Time:82621]
 Iteration 1[342|Time:21164]
 Iteration 2[342|Time:26090]
 Iteration 3[342|Time:26913]
 Iteration 4[342|Time:21839]
 Iteration 5[342|Time:22855]
 Iteration 6[342|Time:24332]
 Iteration 7[342|Time:20163]
 Iteration 8[342|Time:20416]
 Iteration 9[342|Time:19841]
Saving model...done.	Loading model...done.
Processing Sentence: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 Took: 8444


EVALUATION PERFORMANCE:
../testdatav1234/wsj_0602.out.edus: 5 10 vs 8 12
../testdatav1234/wsj_0602.out.edus: 8 12 vs 5 10
../testdatav1234/wsj_0616.out.edus: 4 40 vs 29 50
../testdatav1234/wsj_0616.out.edus: 53 46 vs 29 50
../testdatav1234/wsj_0616.out.edus: 29 50 vs 4 40
../testdatav1234/wsj_0616.out.edus: 29 50 vs 53 46
../testdatav1234/wsj_0616.out.edus: 29 50 vs 46 58
../testdatav1234/wsj_0616.out.edus: 46 58 vs 29 50
../testdatav1234/wsj_0632.out.edus: 37 40 vs 38 42
../testdatav1234/wsj_0632.out.edus: 38 42 vs 37 40
../testdatav1234/wsj_0655.out.edus: 19 16 vs 11 18
../testdatav1234/wsj_0655.out.edus: 11 18 vs 19 16
../testdatav1234/wsj_0655.out.edus: 48 38 vs 32 40
../testdatav1234/wsj_0655.out.edus: 32 40 vs 48 38
../testdatav1234/wsj_0655.out.edus: 40 43 vs 42 48
../testdatav1234/wsj_0655.out.edus: 42 48 vs 40 43
../testdatav1234/wsj_0689.out.edus: 9 7 vs 2 8
../testdatav1234/wsj_0689.out.edus: 2 8 vs 9 7
../testdatav1234/wsj_0689.out.edus: 45 48 vs 46 54
../testdatav1234/wsj_0689.out.edus: 45 50 vs 46 54
../testdatav1234/wsj_0689.out.edus: 46 54 vs 45 48
../testdatav1234/wsj_0689.out.edus: 46 54 vs 45 50
../testdatav1234/wsj_0689.out.edus: 45 94 vs 89 112
../testdatav1234/wsj_0689.out.edus: 89 112 vs 45 94
../testdatav1234/wsj_0689.out.edus: 89 112 vs 94 114
../testdatav1234/wsj_0689.out.edus: 94 114 vs 89 112
../testdatav1234/wsj_1146.out.edus: 258 3 vs 2 186
../testdatav1234/wsj_1146.out.edus: 9 16 vs 12 91
../testdatav1234/wsj_1146.out.edus: 9 27 vs 12 91
../testdatav1234/wsj_1146.out.edus: 258 30 vs 12 91
../testdatav1234/wsj_1146.out.edus: 258 30 vs 9 126
../testdatav1234/wsj_1146.out.edus: 258 30 vs 2 186
../testdatav1234/wsj_1146.out.edus: 258 37 vs 34 41
../testdatav1234/wsj_1146.out.edus: 258 37 vs 12 91
../testdatav1234/wsj_1146.out.edus: 258 37 vs 9 126
../testdatav1234/wsj_1146.out.edus: 258 37 vs 2 186
../testdatav1234/wsj_1146.out.edus: 34 41 vs 258 37
../testdatav1234/wsj_1146.out.edus: 72 74 vs 73 76
../testdatav1234/wsj_1146.out.edus: 73 76 vs 72 74
../testdatav1234/wsj_1146.out.edus: 94 80 vs 12 91
../testdatav1234/wsj_1146.out.edus: 12 91 vs 9 16
../testdatav1234/wsj_1146.out.edus: 12 91 vs 9 27
../testdatav1234/wsj_1146.out.edus: 12 91 vs 258 30
../testdatav1234/wsj_1146.out.edus: 12 91 vs 258 37
../testdatav1234/wsj_1146.out.edus: 12 91 vs 94 80
../testdatav1234/wsj_1146.out.edus: 12 91 vs 88 92
../testdatav1234/wsj_1146.out.edus: 12 91 vs 88 94
../testdatav1234/wsj_1146.out.edus: 88 92 vs 12 91
../testdatav1234/wsj_1146.out.edus: 88 94 vs 12 91
../testdatav1234/wsj_1146.out.edus: 104 96 vs 258 101
../testdatav1234/wsj_1146.out.edus: 104 96 vs 101 105
../testdatav1234/wsj_1146.out.edus: 104 96 vs 101 108
../testdatav1234/wsj_1146.out.edus: 258 101 vs 104 96
../testdatav1234/wsj_1146.out.edus: 258 101 vs 9 126
../testdatav1234/wsj_1146.out.edus: 258 101 vs 2 186
../testdatav1234/wsj_1146.out.edus: 101 105 vs 104 96
../testdatav1234/wsj_1146.out.edus: 101 105 vs 104 118
../testdatav1234/wsj_1146.out.edus: 101 108 vs 104 96
../testdatav1234/wsj_1146.out.edus: 101 108 vs 104 118
../testdatav1234/wsj_1146.out.edus: 104 118 vs 101 105
../testdatav1234/wsj_1146.out.edus: 104 118 vs 101 108
../testdatav1234/wsj_1146.out.edus: 9 126 vs 258 30
../testdatav1234/wsj_1146.out.edus: 9 126 vs 258 37
../testdatav1234/wsj_1146.out.edus: 9 126 vs 258 101
../testdatav1234/wsj_1146.out.edus: 164 157 vs 150 162
../testdatav1234/wsj_1146.out.edus: 150 162 vs 164 157
../testdatav1234/wsj_1146.out.edus: 2 186 vs 258 3
../testdatav1234/wsj_1146.out.edus: 2 186 vs 258 30
../testdatav1234/wsj_1146.out.edus: 2 186 vs 258 37
../testdatav1234/wsj_1146.out.edus: 2 186 vs 258 101
../testdatav1234/wsj_1146.out.edus: 258 254 vs 249 257
../testdatav1234/wsj_1146.out.edus: 249 257 vs 258 254
../testdatav1234/wsj_1146.out.edus: 270 267 vs 261 268
../testdatav1234/wsj_1146.out.edus: 261 268 vs 270 267
../testdatav1234/wsj_1146.out.edus: 292 300 vs 296 302
../testdatav1234/wsj_1146.out.edus: 292 300 vs 296 303
../testdatav1234/wsj_1146.out.edus: 296 302 vs 292 300
../testdatav1234/wsj_1146.out.edus: 296 303 vs 292 300
../testdatav1234/wsj_1148.out.edus: 28 20 vs 15 24
../testdatav1234/wsj_1148.out.edus: 28 20 vs 24 33
../testdatav1234/wsj_1148.out.edus: 28 20 vs 24 36
../testdatav1234/wsj_1148.out.edus: 15 24 vs 28 20
../testdatav1234/wsj_1148.out.edus: 24 33 vs 28 20
../testdatav1234/wsj_1148.out.edus: 24 36 vs 28 20
../testdatav1234/wsj_1189.out.edus: 22 24 vs 23 26
../testdatav1234/wsj_1189.out.edus: 23 26 vs 22 24
../testdatav1234/wsj_1189.out.edus: 49 53 vs 52 65
../testdatav1234/wsj_1189.out.edus: 66 61 vs 52 65
../testdatav1234/wsj_1189.out.edus: 66 64 vs 52 65
../testdatav1234/wsj_1189.out.edus: 52 65 vs 49 53
../testdatav1234/wsj_1189.out.edus: 52 65 vs 66 61
../testdatav1234/wsj_1189.out.edus: 52 65 vs 66 64
../testdatav1234/wsj_1307.out.edus: 2 12 vs 9 16
../testdatav1234/wsj_1307.out.edus: 9 16 vs 2 12
../testdatav1234/wsj_1307.out.edus: 23 27 vs 25 28
../testdatav1234/wsj_1307.out.edus: 25 28 vs 23 27
../testdatav1234/wsj_1307.out.edus: 30 35 vs 31 41
../testdatav1234/wsj_1307.out.edus: 30 37 vs 31 41
../testdatav1234/wsj_1307.out.edus: 31 41 vs 30 35
../testdatav1234/wsj_1307.out.edus: 31 41 vs 30 37
../testdatav1234/wsj_1307.out.edus: 83 81 vs 77 82
../testdatav1234/wsj_1307.out.edus: 77 82 vs 83 81
../testdatav1234/wsj_1331.out.edus: 130 127 vs 123 129
../testdatav1234/wsj_1331.out.edus: 123 129 vs 130 127
../testdatav1234/wsj_1331.out.edus: 145 149 vs 146 152
../testdatav1234/wsj_1331.out.edus: 146 152 vs 145 149
../testdatav1234/wsj_1376.out.edus: 50 48 vs 49 53
../testdatav1234/wsj_1376.out.edus: 41 50 vs 49 53
../testdatav1234/wsj_1376.out.edus: 49 53 vs 50 48
../testdatav1234/wsj_1376.out.edus: 49 53 vs 41 50
../testdatav1234/wsj_1376.out.edus: 49 53 vs 50 57
../testdatav1234/wsj_1376.out.edus: 50 57 vs 49 53
../testdatav1234/wsj_1376.out.edus: 103 98 vs 95 102
../testdatav1234/wsj_1376.out.edus: 103 101 vs 95 102
../testdatav1234/wsj_1376.out.edus: 95 102 vs 103 98
../testdatav1234/wsj_1376.out.edus: 95 102 vs 103 101
../testdatav1234/wsj_1376.out.edus: 5 109 vs 95 165
../testdatav1234/wsj_1376.out.edus: 120 122 vs 121 123
../testdatav1234/wsj_1376.out.edus: 120 122 vs 121 127
../testdatav1234/wsj_1376.out.edus: 121 123 vs 120 122
../testdatav1234/wsj_1376.out.edus: 121 127 vs 120 122
../testdatav1234/wsj_1376.out.edus: 95 165 vs 5 109
../testdatav1234/wsj_1376.out.edus: 5 177 vs 172 178
../testdatav1234/wsj_1376.out.edus: 172 178 vs 5 177
../testdatav1234/wsj_1387.out.edus: 94 96 vs 95 97
../testdatav1234/wsj_1387.out.edus: 95 97 vs 94 96
../testdatav1234/wsj_1387.out.edus: 117 119 vs 118 120
../testdatav1234/wsj_1387.out.edus: 118 120 vs 117 119
../testdatav1234/wsj_2386.out.edus: 59 66 vs 61 72
../testdatav1234/wsj_2386.out.edus: 61 72 vs 59 66
../testdatav1234/wsj_2386.out.edus: 74 76 vs 75 79
../testdatav1234/wsj_2386.out.edus: 75 79 vs 74 76
Tokens: 2346
Correct: 1708
Unlabeled Accuracy: 0.7280477408354646
Unlabeled Complete Correct: 0.05263157894736842
Labeled Accuracy: 0.479539641943734
Labeled Complete Correct: 0.02631578947368421

This is output from my evaluator.
Span precision/recall: 0.6386892177589852
Nuclearity precision/recall: 0.5596194503171248
Relation precision/recall: 0.46617336152219874
End for my evalutor.


PERFORMANCE VERSION2
Tokens: 2346
Correct: 2346
Unlabeled Accuracy: 1.0
Unlabeled Complete Correct: 1.0
Labeled Accuracy: 0.5903665814151747
Labeled Complete Correct: 0.02631578947368421
train 18 projective model
Creating Alphabet ... Done.
Num Features: 434764
Creating Feature Vector Instances: 
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 
Num Features: 434764
Num Feats: 434764.	Num Edge Labels: 20
 Iteration 0[342|Time:117130]
 Iteration 1[342|Time:109944]
 Iteration 2[342|Time:109684]
 Iteration 3[342|Time:111347]
 Iteration 4[342|Time:104424]
 Iteration 5[342|Time:109327]
 Iteration 6[342|Time:99792]
 Iteration 7[342|Time:98328]
 Iteration 8[342|Time:97815]
 Iteration 9[342|Time:110962]
Saving model...done.	Loading model...done.
Processing Sentence: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 Took: 29222


EVALUATION PERFORMANCE:
Tokens: 2346
Correct: 1729
Unlabeled Accuracy: 0.736999147485081
Unlabeled Complete Correct: 0.05263157894736842
Labeled Accuracy: 0.48678601875532823
Labeled Complete Correct: 0.02631578947368421

This is output from my evaluator.
Span precision/recall: 0.8234672304439746
Nuclearity precision/recall: 0.7177589852008457
Relation precision/recall: 0.5976744186046512
End for my evalutor.


PERFORMANCE VERSION2
Tokens: 2346
Correct: 2346
Unlabeled Accuracy: 1.0
Unlabeled Complete Correct: 1.0
Labeled Accuracy: 0.5907928388746803
Labeled Complete Correct: 0.02631578947368421
train 110 non-projective model
Creating Alphabet ... Done.
Num Features: 513292
Creating Feature Vector Instances: 
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 
Num Features: 513292
Num Feats: 513292.	Num Edge Labels: 111
 Iteration 0[342|Time:47551]
 Iteration 1[342|Time:45336]
 Iteration 2[342|Time:48221]
 Iteration 3[342|Time:47256]
 Iteration 4[342|Time:65644]
 Iteration 5[342|Time:63043]
 Iteration 6[342|Time:48640]
 Iteration 7[342|Time:46756]
 Iteration 8[342|Time:46836]
 Iteration 9[342|Time:47277]
Saving model...done.	Loading model...done.
Processing Sentence: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 Took: 30506


EVALUATION PERFORMANCE:
../testdatav1234/wsj_0627.out.edus: 23 21 vs 22 24
../testdatav1234/wsj_0627.out.edus: 19 23 vs 22 24
../testdatav1234/wsj_0627.out.edus: 22 24 vs 23 21
../testdatav1234/wsj_0627.out.edus: 22 24 vs 19 23
../testdatav1234/wsj_0627.out.edus: 22 24 vs 23 35
../testdatav1234/wsj_0627.out.edus: 2 27 vs 23 35
../testdatav1234/wsj_0627.out.edus: 23 35 vs 22 24
../testdatav1234/wsj_0627.out.edus: 23 35 vs 2 27
../testdatav1234/wsj_0627.out.edus: 35 38 vs 37 40
../testdatav1234/wsj_0627.out.edus: 37 40 vs 35 38
../testdatav1234/wsj_0655.out.edus: 2 25 vs 20 32
../testdatav1234/wsj_0655.out.edus: 20 32 vs 2 25
../testdatav1234/wsj_0655.out.edus: 48 38 vs 37 39
../testdatav1234/wsj_0655.out.edus: 37 39 vs 48 38
../testdatav1234/wsj_1142.out.edus: 45 52 vs 49 57
../testdatav1234/wsj_1142.out.edus: 45 52 vs 49 66
../testdatav1234/wsj_1142.out.edus: 45 52 vs 49 85
../testdatav1234/wsj_1142.out.edus: 49 57 vs 45 52
../testdatav1234/wsj_1142.out.edus: 45 58 vs 49 66
../testdatav1234/wsj_1142.out.edus: 45 58 vs 49 85
../testdatav1234/wsj_1142.out.edus: 49 66 vs 45 52
../testdatav1234/wsj_1142.out.edus: 49 66 vs 45 58
../testdatav1234/wsj_1142.out.edus: 49 85 vs 45 52
../testdatav1234/wsj_1142.out.edus: 49 85 vs 45 58
../testdatav1234/wsj_1146.out.edus: 16 26 vs 21 27
../testdatav1234/wsj_1146.out.edus: 21 27 vs 16 26
../testdatav1234/wsj_1146.out.edus: 9 30 vs 16 164
../testdatav1234/wsj_1146.out.edus: 258 37 vs 9 118
../testdatav1234/wsj_1146.out.edus: 258 37 vs 9 150
../testdatav1234/wsj_1146.out.edus: 258 37 vs 16 164
../testdatav1234/wsj_1146.out.edus: 258 37 vs 9 174
../testdatav1234/wsj_1146.out.edus: 72 74 vs 73 76
../testdatav1234/wsj_1146.out.edus: 73 76 vs 72 74
../testdatav1234/wsj_1146.out.edus: 94 80 vs 258 88
../testdatav1234/wsj_1146.out.edus: 258 88 vs 94 80
../testdatav1234/wsj_1146.out.edus: 258 88 vs 9 118
../testdatav1234/wsj_1146.out.edus: 258 88 vs 9 150
../testdatav1234/wsj_1146.out.edus: 258 88 vs 16 164
../testdatav1234/wsj_1146.out.edus: 258 88 vs 9 174
../testdatav1234/wsj_1146.out.edus: 104 96 vs 118 101
../testdatav1234/wsj_1146.out.edus: 104 96 vs 101 108
../testdatav1234/wsj_1146.out.edus: 118 101 vs 104 96
../testdatav1234/wsj_1146.out.edus: 101 108 vs 104 96
../testdatav1234/wsj_1146.out.edus: 9 118 vs 258 37
../testdatav1234/wsj_1146.out.edus: 9 118 vs 258 88
../testdatav1234/wsj_1146.out.edus: 9 118 vs 16 164
../testdatav1234/wsj_1146.out.edus: 9 150 vs 258 37
../testdatav1234/wsj_1146.out.edus: 9 150 vs 258 88
../testdatav1234/wsj_1146.out.edus: 9 150 vs 16 164
../testdatav1234/wsj_1146.out.edus: 16 164 vs 9 30
../testdatav1234/wsj_1146.out.edus: 16 164 vs 258 37
../testdatav1234/wsj_1146.out.edus: 16 164 vs 258 88
../testdatav1234/wsj_1146.out.edus: 16 164 vs 9 118
../testdatav1234/wsj_1146.out.edus: 16 164 vs 9 150
../testdatav1234/wsj_1146.out.edus: 9 174 vs 258 37
../testdatav1234/wsj_1146.out.edus: 9 174 vs 258 88
../testdatav1234/wsj_1146.out.edus: 244 246 vs 245 247
../testdatav1234/wsj_1146.out.edus: 245 247 vs 244 246
../testdatav1234/wsj_1146.out.edus: 258 254 vs 249 257
../testdatav1234/wsj_1146.out.edus: 258 255 vs 249 257
../testdatav1234/wsj_1146.out.edus: 249 257 vs 258 254
../testdatav1234/wsj_1146.out.edus: 249 257 vs 258 255
../testdatav1234/wsj_1146.out.edus: 300 296 vs 287 299
../testdatav1234/wsj_1146.out.edus: 287 299 vs 300 296
../testdatav1234/wsj_1146.out.edus: 287 299 vs 296 302
../testdatav1234/wsj_1146.out.edus: 287 299 vs 296 303
../testdatav1234/wsj_1146.out.edus: 296 302 vs 287 299
../testdatav1234/wsj_1146.out.edus: 296 303 vs 287 299
../testdatav1234/wsj_1189.out.edus: 18 20 vs 19 21
../testdatav1234/wsj_1189.out.edus: 19 21 vs 18 20
../testdatav1234/wsj_1306.out.edus: 17 20 vs 19 21
../testdatav1234/wsj_1306.out.edus: 19 21 vs 17 20
../testdatav1234/wsj_1307.out.edus: 67 64 vs 60 65
../testdatav1234/wsj_1307.out.edus: 60 65 vs 67 64
../testdatav1234/wsj_1307.out.edus: 60 65 vs 64 68
../testdatav1234/wsj_1307.out.edus: 64 68 vs 60 65
../testdatav1234/wsj_1307.out.edus: 83 81 vs 82 87
../testdatav1234/wsj_1307.out.edus: 73 83 vs 82 87
../testdatav1234/wsj_1307.out.edus: 82 87 vs 83 81
../testdatav1234/wsj_1307.out.edus: 82 87 vs 73 83
../testdatav1234/wsj_1331.out.edus: 2 44 vs 43 64
../testdatav1234/wsj_1331.out.edus: 43 64 vs 2 44
../testdatav1234/wsj_1331.out.edus: 43 64 vs 44 79
../testdatav1234/wsj_1331.out.edus: 43 64 vs 57 113
../testdatav1234/wsj_1331.out.edus: 2 72 vs 44 79
../testdatav1234/wsj_1331.out.edus: 2 72 vs 57 113
../testdatav1234/wsj_1331.out.edus: 44 79 vs 43 64
../testdatav1234/wsj_1331.out.edus: 44 79 vs 2 72
../testdatav1234/wsj_1331.out.edus: 44 79 vs 57 113
../testdatav1234/wsj_1331.out.edus: 2 107 vs 57 113
../testdatav1234/wsj_1331.out.edus: 57 113 vs 43 64
../testdatav1234/wsj_1331.out.edus: 57 113 vs 2 72
../testdatav1234/wsj_1331.out.edus: 57 113 vs 44 79
../testdatav1234/wsj_1331.out.edus: 57 113 vs 2 107
../testdatav1234/wsj_1331.out.edus: 146 148 vs 147 149
../testdatav1234/wsj_1331.out.edus: 147 149 vs 146 148
../testdatav1234/wsj_1346.out.edus: 7 12 vs 10 13
../testdatav1234/wsj_1346.out.edus: 7 12 vs 10 14
../testdatav1234/wsj_1346.out.edus: 10 13 vs 7 12
../testdatav1234/wsj_1346.out.edus: 10 14 vs 7 12
../testdatav1234/wsj_1376.out.edus: 103 101 vs 98 102
../testdatav1234/wsj_1376.out.edus: 98 102 vs 103 101
../testdatav1234/wsj_1376.out.edus: 95 104 vs 103 109
../testdatav1234/wsj_1376.out.edus: 103 109 vs 95 104
../testdatav1234/wsj_1376.out.edus: 5 165 vs 85 179
../testdatav1234/wsj_1376.out.edus: 5 177 vs 85 179
../testdatav1234/wsj_1376.out.edus: 85 179 vs 5 165
../testdatav1234/wsj_1376.out.edus: 85 179 vs 5 177
../testdatav1234/wsj_1387.out.edus: 3 89 vs 64 116
../testdatav1234/wsj_1387.out.edus: 64 116 vs 3 89
../testdatav1234/wsj_1387.out.edus: 117 119 vs 118 120
../testdatav1234/wsj_1387.out.edus: 118 120 vs 117 119
../testdatav1234/wsj_2386.out.edus: 51 56 vs 53 59
../testdatav1234/wsj_2386.out.edus: 53 59 vs 51 56
../testdatav1234/wsj_2386.out.edus: 74 82 vs 79 93
../testdatav1234/wsj_2386.out.edus: 74 91 vs 79 93
../testdatav1234/wsj_2386.out.edus: 79 93 vs 74 82
../testdatav1234/wsj_2386.out.edus: 79 93 vs 74 91
Tokens: 2346
Correct: 1752
Unlabeled Accuracy: 0.7468030690537084
Unlabeled Complete Correct: 0.02631578947368421
Labeled Accuracy: 0.407075873827792
Labeled Complete Correct: 0.02631578947368421

This is output from my evaluator.
Span precision/recall: 0.6575052854122622
Nuclearity precision/recall: 0.5826638477801268
Relation precision/recall: 0.45856236786469345
End for my evalutor.


PERFORMANCE VERSION2
Tokens: 2346
Correct: 2346
Unlabeled Accuracy: 1.0
Unlabeled Complete Correct: 1.0
Labeled Accuracy: 0.4833759590792839
Labeled Complete Correct: 0.02631578947368421
train 110 projective model
Creating Alphabet ... Done.
Num Features: 513292
Creating Feature Vector Instances: 
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 
Num Features: 513292
Num Feats: 513292.	Num Edge Labels: 111
 Iteration 0[342|Time:139160]
 Iteration 1[342|Time:140706]
 Iteration 2[342|Time:139112]
 Iteration 3[342|Time:137683]
 Iteration 4[342|Time:136178]
 Iteration 5[342|Time:135759]
 Iteration 6[342|Time:137731]
 Iteration 7[342|Time:136824]
 Iteration 8[342|Time:136355]
 Iteration 9[342|Time:131398]
Saving model...done.	Loading model...done.
Processing Sentence: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 Took: 49503


EVALUATION PERFORMANCE:
Tokens: 2346
Correct: 1753
Unlabeled Accuracy: 0.7472293265132139
Unlabeled Complete Correct: 0.05263157894736842
Labeled Accuracy: 0.4040920716112532
Labeled Complete Correct: 0.02631578947368421

This is output from my evaluator.
Span precision/recall: 0.8306553911205073
Nuclearity precision/recall: 0.73276955602537
Relation precision/recall: 0.5699788583509514
End for my evalutor.


PERFORMANCE VERSION2
Tokens: 2346
Correct: 2346
Unlabeled Accuracy: 1.0
Unlabeled Complete Correct: 1.0
Labeled Accuracy: 0.47698209718670076
Labeled Complete Correct: 0.02631578947368421
test 18 non-projective model
test 18 projective model
test 110 non-projective model
test 110 projective model
